---
sidebar_position: 11
---

# Convexity of Functions

A function $f$ is called **convex** on an interval $I$ if for all $x_1, x_2 \in I$ and all $t$ with $0 < t < 1$, we have

$$
\begin{equation*}
f((1-t)x_1 + t x_2) \le (1-t) f(x_1) + t f(x_2).
\end{equation*}
$$

If equality occurs **only when** $x_1 = x_2$, then $f$ is called **strictly convex**.

If $-f$ is convex (strictly convex) on $I$, then $f$ is **concave (strictly concave)** on $I$.

When $f$ is convex (concave), the graph $y = f(x)$ is said to be **convex upward** (resp. **convex downward**).



## Theorems

1. On an interval $I$,

	$$
	\begin{equation*}
	f'' \ge 0 \;\Longleftrightarrow\;
	\text{a twice differentiable function } f \text{ is convex on } I.
	\end{equation*}
	$$

	The derivative $f'$ is non-decreasing (strictly increasing) on $I$

	$$
	\begin{equation*}
	\Longleftrightarrow
	\end{equation*}
	$$

	a differentiable function $f$ is convex (strictly convex) on $I$.



2. If $x_0$ is a critical point of a differentiable **convex** function $f$,  then $x_0$ is a **point of minimum** of $f$.



3. If a convex function $f$ is differentiable at $x_0$,  then the graph $y = f(x)$ lies **above** its tangent line at $x_0$:
	$$
	\begin{equation*}
	f(x) \ge f(x_0) + f'(x_0)(x - x_0), \quad \forall x.
	\end{equation*}
	$$



## Global convergence of newton's method

Let $f$ be a convex function differentiable on the open interval $(a,b)$, with

$$
\begin{equation*}
f'(x) > 0,\qquad f(a) < 0 < f(b).
\end{equation*}
$$

Then for any $x_0 \in (a,b)$, as long as $f(x_0) > 0$, the Newton iteration

$$
\begin{equation*}
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\end{equation*}
$$

necessarily converges to the zero of $f$.



## Jensen's inequality

Let $f$ be a convex function on an interval $I$.  Then for any $x_1, x_2, \ldots, x_n \in I$ and any positive weights $t_1, t_2, \ldots, t_n$, we have

$$
\begin{equation*}
f\!\left( 
\frac{t_1 x_1 + t_2 x_2 + \cdots + t_n x_n}{t_1 + t_2 + \cdots + t_n}
\right)
\le
\frac{
t_1 f(x_1) + t_2 f(x_2) + \cdots + t_n f(x_n)
}{
t_1 + t_2 + \cdots + t_n
}.
\end{equation*}
$$

If $f$ is strictly convex, then equality holds **only if**

$$
\begin{equation*}
x_1 = x_2 = \cdots = x_n.
\end{equation*}
$$


## HÃ¶lder's inequality

For positive numbers $a_1, a_2, \ldots, a_n$ and $b_1, b_2, \ldots, b_n$,  and for $p, q > 1$ satisfying $\tfrac{1}{p} + \tfrac{1}{q} = 1$, we have

$$
\begin{equation*}
\sum_{k=1}^n a_k b_k
\le
\left( \sum_{k=1}^n a_k^p \right)^{1/p}
\left( \sum_{k=1}^n b_k^q \right)^{1/q}.
\end{equation*}
$$


## Minkowski's inequality

For positive numbers $a_1, a_2, \ldots, a_n$ and $b_1, b_2, \ldots, b_n$,  and for $p \ge 1$, we have

$$
\begin{equation*}
\left( \sum_{k=1}^n (a_k + b_k)^p \right)^{1/p}
\le
\left( \sum_{k=1}^n a_k^p \right)^{1/p}
+
\left( \sum_{k=1}^n b_k^p \right)^{1/p}.
\end{equation*}
$$
